{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPD1s8qAxXT2Ac10R6/7y/4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"50f9dadb12df4a4b9a80eff37f69e189":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_444bd697e26d41049cec8fcb23e52f2e","IPY_MODEL_ff24586a8263408aa8c998483f3949bd","IPY_MODEL_e95a5d1dd0c048aaa65956fb57071f8e"],"layout":"IPY_MODEL_221161b3ad3e46e4b068f4b3d29c3e61"}},"444bd697e26d41049cec8fcb23e52f2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd0f6751e1334aca9621b1cbf94f3325","placeholder":"‚Äã","style":"IPY_MODEL_a6ca0d5e0e0f4c2c91f321bc3d2a730c","value":"Generating‚Äátrain‚Äásplit:‚Äá"}},"ff24586a8263408aa8c998483f3949bd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c02e957c00047c6ba408209138bcf5b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3e268c3f78a345489bbf3f0ccd0db65e","value":1}},"e95a5d1dd0c048aaa65956fb57071f8e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf9071dc06d141a89bd313aeddef1a1e","placeholder":"‚Äã","style":"IPY_MODEL_988339302cfa43b5a9519ccf16940c52","value":"‚Äá2000/0‚Äá[00:00&lt;00:00,‚Äá19772.51‚Äáexamples/s]"}},"221161b3ad3e46e4b068f4b3d29c3e61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd0f6751e1334aca9621b1cbf94f3325":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6ca0d5e0e0f4c2c91f321bc3d2a730c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c02e957c00047c6ba408209138bcf5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"3e268c3f78a345489bbf3f0ccd0db65e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cf9071dc06d141a89bd313aeddef1a1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"988339302cfa43b5a9519ccf16940c52":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2ed7885d5035431ea1b47ca9386377d8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_db90343e54014b249a3d8bd1ed0ecb11","IPY_MODEL_919571d378cc4fc695cdb8f77cceb044","IPY_MODEL_7f646b0dcfc04f8d85416bdadacce6ca"],"layout":"IPY_MODEL_eb7c52a80b5e4566ae86723bfe321c4f"}},"db90343e54014b249a3d8bd1ed0ecb11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f78a2ccb055846188f161767ece03d6c","placeholder":"‚Äã","style":"IPY_MODEL_7b0ecc01c52c45a5a1ff2adf12ecb775","value":"Map:‚Äá100%"}},"919571d378cc4fc695cdb8f77cceb044":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7df0d720cb1045319d2bb4c385d33aa9","max":2000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1f3616afacfc45efa2bff30549833658","value":2000}},"7f646b0dcfc04f8d85416bdadacce6ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8189dca297b349868cfb46b53886ed50","placeholder":"‚Äã","style":"IPY_MODEL_2a91e0c20d0d4fa5aa6f7f323ee1db2c","value":"‚Äá2000/2000‚Äá[00:00&lt;00:00,‚Äá10780.21‚Äáexamples/s]"}},"eb7c52a80b5e4566ae86723bfe321c4f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f78a2ccb055846188f161767ece03d6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b0ecc01c52c45a5a1ff2adf12ecb775":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7df0d720cb1045319d2bb4c385d33aa9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f3616afacfc45efa2bff30549833658":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8189dca297b349868cfb46b53886ed50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a91e0c20d0d4fa5aa6f7f323ee1db2c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"883367a2ebcf40b19b735f1ad3b520f8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_13f04d24de74454aa3e7656b33f33620","IPY_MODEL_e72d34b942914b2c84b8b1fe2d2dd036","IPY_MODEL_8eeb3365303a434a9d3793f5b92b200f"],"layout":"IPY_MODEL_c5761fc671c54160b333eac8af8b522f"}},"13f04d24de74454aa3e7656b33f33620":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_008c17fb736c44aa906acdf674c9f29f","placeholder":"‚Äã","style":"IPY_MODEL_d6d3a93b10744b3387b306930f679af7","value":"Unsloth:‚ÄáTokenizing‚Äá[&quot;text&quot;]‚Äá(num_proc=6):‚Äá100%"}},"e72d34b942914b2c84b8b1fe2d2dd036":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ae803ca2eab4d8c83ed586f8dbe31fc","max":1800,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4d7a70d142114085b3b0acd0d577e7ec","value":1800}},"8eeb3365303a434a9d3793f5b92b200f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10135547a9874295b59c1c3c9492d062","placeholder":"‚Äã","style":"IPY_MODEL_70e15ff6ed1a455d9adf4bfea1d3b747","value":"‚Äá1800/1800‚Äá[00:18&lt;00:00,‚Äá159.80‚Äáexamples/s]"}},"c5761fc671c54160b333eac8af8b522f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"008c17fb736c44aa906acdf674c9f29f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6d3a93b10744b3387b306930f679af7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ae803ca2eab4d8c83ed586f8dbe31fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d7a70d142114085b3b0acd0d577e7ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"10135547a9874295b59c1c3c9492d062":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70e15ff6ed1a455d9adf4bfea1d3b747":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dbdc285d574e408b841830f8accd4301":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_488bed541d1543cf9d6ebfbf909e6f97","IPY_MODEL_e8189d4edf7243d181f118ffbb964fa6","IPY_MODEL_2674c0ecdab34d2c9b9ea513a34f531a"],"layout":"IPY_MODEL_dd08e58f3c4043edb7d51253f3a20424"}},"488bed541d1543cf9d6ebfbf909e6f97":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a052cffd242e4e0ca9bcc3b97f33c23e","placeholder":"‚Äã","style":"IPY_MODEL_26e896452aa4406689f729175f33ea72","value":"Unsloth:‚ÄáTokenizing‚Äá[&quot;text&quot;]‚Äá(num_proc=6):‚Äá100%"}},"e8189d4edf7243d181f118ffbb964fa6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca473ed971ed463a8f4c91e9b2e92c33","max":200,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5b79f0256f444de2b52ee977f4426d7e","value":200}},"2674c0ecdab34d2c9b9ea513a34f531a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f511889645db430d814cddb171c192a3","placeholder":"‚Äã","style":"IPY_MODEL_43858ed2b4a44878b71336a6e57313f1","value":"‚Äá200/200‚Äá[00:13&lt;00:00,‚Äá25.27‚Äáexamples/s]"}},"dd08e58f3c4043edb7d51253f3a20424":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a052cffd242e4e0ca9bcc3b97f33c23e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26e896452aa4406689f729175f33ea72":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca473ed971ed463a8f4c91e9b2e92c33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b79f0256f444de2b52ee977f4426d7e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f511889645db430d814cddb171c192a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43858ed2b4a44878b71336a6e57313f1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"vH4Bzis5BrLb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762263535392,"user_tz":-330,"elapsed":130,"user":{"displayName":"Ayush Bhakat","userId":"01025510492377215074"}},"outputId":"e5e281f1-ade4-4913-9f0b-4da967601628"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Nov  4 13:38:55 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","source":["%%capture\n","# Install Unsloth - optimized for faster LLM training\n","!pip install unsloth\n","\n","# Install required dependencies\n","!pip install --no-deps trl peft accelerate bitsandbytes"],"metadata":{"id":"GGeYkn1vEX8m","executionInfo":{"status":"ok","timestamp":1762263559094,"user_tz":-330,"elapsed":15837,"user":{"displayName":"Ayush Bhakat","userId":"01025510492377215074"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import torch\n","print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n","print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n","print(f\"‚úÖ CUDA version: {torch.version.cuda}\")\n","\n","# Try importing unsloth\n","try:\n","    from unsloth import FastLanguageModel\n","    print(\"‚úÖ Unsloth imported successfully!\")\n","except Exception as e:\n","    print(f\"‚ùå Error: {e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ujD9xMIHFrqG","executionInfo":{"status":"ok","timestamp":1762263640110,"user_tz":-330,"elapsed":61422,"user":{"displayName":"Ayush Bhakat","userId":"01025510492377215074"}},"outputId":"1edbed74-dd27-4905-9dac-b5dc98a85642"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ PyTorch version: 2.8.0+cu126\n","‚úÖ CUDA available: True\n","‚úÖ CUDA version: 12.6\n","ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","ü¶• Unsloth Zoo will now patch everything to make training faster!\n","‚úÖ Unsloth imported successfully!\n"]}]},{"cell_type":"code","source":["import os\n","\n","# Check if file exists\n","if os.path.exists('hider_raw.jsonl'):\n","    file_size = os.path.getsize('hider_raw.jsonl') / (1024 * 1024)  # Convert to MB\n","    print(f\"‚úÖ File uploaded successfully!\")\n","    print(f\"   File size: {file_size:.2f} MB\")\n","\n","    # Count number of examples\n","    import json\n","    with open('hider_raw.jsonl', 'r') as f:\n","        num_examples = sum(1 for line in f)\n","    print(f\"   Number of training examples: {num_examples}\")\n","else:\n","    print(\"‚ùå File not found! Please upload hider_raw.jsonl\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJN8YaYxEanr","executionInfo":{"status":"ok","timestamp":1762276029814,"user_tz":-330,"elapsed":20,"user":{"displayName":"Ayush Bhakat","userId":"01025510492377215074"}},"outputId":"fbd76ee0-589d-4431-bff0-0a48c7538a87"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ File uploaded successfully!\n","   File size: 2.11 MB\n","   Number of training examples: 2000\n"]}]},{"cell_type":"code","source":["import os\n","import json\n","import torch\n","from datasets import load_dataset\n","from unsloth import FastLanguageModel\n","from trl import SFTTrainer\n","from transformers import TrainingArguments\n","\n","DATA_FILE = 'hider_raw.jsonl'\n","MODEL_NAME = 'unsloth/gemma-3-270m-it'  # Unsloth's optimized Gemma 3 270M\n","OUTPUT_DIR = 'models/hider_sft'\n","MAX_SEQ_LENGTH = 2048\n","EPOCHS = 15\n","BATCH_SIZE = 4\n","LEARNING_RATE = 2e-4\n","LORA_R = 16\n","LORA_ALPHA = 16\n","\n","# ============================================================================\n","# STEP 1: LOAD MODEL AND TOKENIZER\n","# ============================================================================\n","\n","print(\"=\"*70)\n","print(\"ü¶• LOADING GEMMA 3 270M WITH UNSLOTH\")\n","print(\"=\"*70)\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name=MODEL_NAME,\n","    max_seq_length=MAX_SEQ_LENGTH,\n","    dtype=None,  # Auto-detect best dtype\n","    load_in_4bit=False,  # 4-bit quantization for memory efficiency\n",")\n","\n","print(\"‚úÖ Model loaded successfully!\")\n","print(f\"   Model: {MODEL_NAME}\")\n","print(f\"   Max sequence length: {MAX_SEQ_LENGTH}\")\n","print(f\"   Using 4-bit quantization\")\n","\n","# ============================================================================\n","# STEP 2: APPLY LORA\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"üéØ APPLYING LORA\")\n","print(\"=\"*70)\n","\n","model = FastLanguageModel.get_peft_model(\n","    model,\n","    r=LORA_R,\n","    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                   \"gate_proj\", \"up_proj\", \"down_proj\"],\n","    lora_alpha=LORA_ALPHA,\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    use_gradient_checkpointing=\"unsloth\",  # Unsloth's optimized checkpointing\n","    random_state=42,\n","    use_rslora=False,\n",")\n","\n","print(\"‚úÖ LoRA applied successfully!\")\n","print(f\"   LoRA rank: {LORA_R}\")\n","print(f\"   LoRA alpha: {LORA_ALPHA}\")\n","print(f\"   Target modules: q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj\")\n","\n","# ============================================================================\n","# STEP 3: LOAD AND PREPARE DATASET\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"üìä LOADING DATASET\")\n","print(\"=\"*70)\n","\n","# Load JSONL file\n","dataset = load_dataset('json', data_files=DATA_FILE, split='train')\n","print(f\"‚úÖ Loaded {len(dataset)} examples\")\n","\n","# Format dataset using chat template\n","def format_example(example):\n","    messages = example['messages']\n","\n","    text = f\"{messages[0]['content']}\\n\\n\"  # System\n","    text += f\"{messages[1]['content']}\\n\\n\"  # User\n","    text += f\"{messages[2]['content']}\"  # Assistant\n","\n","    # Add EOS token so model learns to stop generating\n","    text += tokenizer.eos_token\n","\n","    return {\"text\": text}\n","\n","print(\"   Formatting examples with chat template...\")\n","dataset = dataset.map(format_example, remove_columns=dataset.column_names)\n","\n","# Split into train/eval (90/10)\n","dataset = dataset.train_test_split(test_size=0.1, seed=42)\n","train_dataset = dataset['train']\n","eval_dataset = dataset['test']\n","\n","print(f\"‚úÖ Dataset prepared:\")\n","print(f\"   Training examples: {len(train_dataset)}\")\n","print(f\"   Evaluation examples: {len(eval_dataset)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":708,"referenced_widgets":["50f9dadb12df4a4b9a80eff37f69e189","444bd697e26d41049cec8fcb23e52f2e","ff24586a8263408aa8c998483f3949bd","e95a5d1dd0c048aaa65956fb57071f8e","221161b3ad3e46e4b068f4b3d29c3e61","cd0f6751e1334aca9621b1cbf94f3325","a6ca0d5e0e0f4c2c91f321bc3d2a730c","2c02e957c00047c6ba408209138bcf5b","3e268c3f78a345489bbf3f0ccd0db65e","cf9071dc06d141a89bd313aeddef1a1e","988339302cfa43b5a9519ccf16940c52","2ed7885d5035431ea1b47ca9386377d8","db90343e54014b249a3d8bd1ed0ecb11","919571d378cc4fc695cdb8f77cceb044","7f646b0dcfc04f8d85416bdadacce6ca","eb7c52a80b5e4566ae86723bfe321c4f","f78a2ccb055846188f161767ece03d6c","7b0ecc01c52c45a5a1ff2adf12ecb775","7df0d720cb1045319d2bb4c385d33aa9","1f3616afacfc45efa2bff30549833658","8189dca297b349868cfb46b53886ed50","2a91e0c20d0d4fa5aa6f7f323ee1db2c"]},"id":"EZEh5cg4EdYo","executionInfo":{"status":"ok","timestamp":1762276063685,"user_tz":-330,"elapsed":23724,"user":{"displayName":"Ayush Bhakat","userId":"01025510492377215074"}},"outputId":"66c9580b-f1d4-4e1d-a8af-350bfab86292"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","ü¶• LOADING GEMMA 3 270M WITH UNSLOTH\n","======================================================================\n","==((====))==  Unsloth 2025.11.1: Fast Gemma3 patching. Transformers: 4.57.1.\n","   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.32.post2. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","Unsloth: Using float16 precision for gemma3 won't work! Using float32.\n","Unsloth: Gemma3 does not support SDPA - switching to fast eager.\n","Unsloth: QLoRA and full finetuning all not selected. Switching to 16bit LoRA.\n","‚úÖ Model loaded successfully!\n","   Model: unsloth/gemma-3-270m-it\n","   Max sequence length: 2048\n","   Using 4-bit quantization\n","\n","======================================================================\n","üéØ APPLYING LORA\n","======================================================================\n","Unsloth: Making `model.base_model.model.model` require gradients\n","‚úÖ LoRA applied successfully!\n","   LoRA rank: 16\n","   LoRA alpha: 16\n","   Target modules: q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj\n","\n","======================================================================\n","üìä LOADING DATASET\n","======================================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50f9dadb12df4a4b9a80eff37f69e189"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úÖ Loaded 2000 examples\n","   Formatting examples with chat template...\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ed7885d5035431ea1b47ca9386377d8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚úÖ Dataset prepared:\n","   Training examples: 1800\n","   Evaluation examples: 200\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 4: CONFIGURE TRAINING\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"‚öôÔ∏è CONFIGURING TRAINING\")\n","print(\"=\"*70)\n","\n","training_args = TrainingArguments(\n","    output_dir=OUTPUT_DIR,\n","    num_train_epochs=EPOCHS,\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    gradient_accumulation_steps=8,  # Effective batch = 8 * 2 = 16\n","    learning_rate=LEARNING_RATE,\n","    weight_decay=0.01,\n","    logging_steps=10,\n","    save_steps=100,\n","    eval_steps=100,\n","    eval_strategy=\"steps\",\n","    save_strategy=\"steps\",\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"eval_loss\",\n","    greater_is_better=False,\n","    warmup_steps=50,\n","    lr_scheduler_type=\"cosine\",\n","    fp16=not torch.cuda.is_bf16_supported(),\n","    bf16=torch.cuda.is_bf16_supported(),\n","    optim=\"adamw_8bit\",  # Unsloth optimized optimizer\n","    report_to=\"none\",\n","    push_to_hub=False,\n","    save_total_limit=3,\n",")\n","\n","print(f\"‚úÖ Training configuration:\")\n","print(f\"   Epochs: {EPOCHS}\")\n","print(f\"   Batch size: {BATCH_SIZE}\")\n","print(f\"   Gradient accumulation: 8 (effective batch size: 16)\")\n","print(f\"   Learning rate: {LEARNING_RATE}\")\n","print(f\"   Optimizer: adamw_8bit\")\n","print(f\"   Scheduler: cosine\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PowIcNogEhi6","executionInfo":{"status":"ok","timestamp":1762276067078,"user_tz":-330,"elapsed":28,"user":{"displayName":"Ayush Bhakat","userId":"01025510492377215074"}},"outputId":"e0abdd15-9fd0-4b4f-f3f4-7a7a10e38891"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","‚öôÔ∏è CONFIGURING TRAINING\n","======================================================================\n","‚úÖ Training configuration:\n","   Epochs: 15\n","   Batch size: 4\n","   Gradient accumulation: 8 (effective batch size: 16)\n","   Learning rate: 0.0002\n","   Optimizer: adamw_8bit\n","   Scheduler: cosine\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 5: CREATE TRAINER\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"üöÄ INITIALIZING TRAINER\")\n","print(\"=\"*70)\n","\n","trainer = SFTTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    tokenizer=tokenizer,\n","    dataset_text_field=\"text\",\n","    max_seq_length=MAX_SEQ_LENGTH,\n","    packing=False,\n",")\n","\n","print(\"‚úÖ Trainer initialized!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226,"referenced_widgets":["883367a2ebcf40b19b735f1ad3b520f8","13f04d24de74454aa3e7656b33f33620","e72d34b942914b2c84b8b1fe2d2dd036","8eeb3365303a434a9d3793f5b92b200f","c5761fc671c54160b333eac8af8b522f","008c17fb736c44aa906acdf674c9f29f","d6d3a93b10744b3387b306930f679af7","8ae803ca2eab4d8c83ed586f8dbe31fc","4d7a70d142114085b3b0acd0d577e7ec","10135547a9874295b59c1c3c9492d062","70e15ff6ed1a455d9adf4bfea1d3b747","dbdc285d574e408b841830f8accd4301","488bed541d1543cf9d6ebfbf909e6f97","e8189d4edf7243d181f118ffbb964fa6","2674c0ecdab34d2c9b9ea513a34f531a","dd08e58f3c4043edb7d51253f3a20424","a052cffd242e4e0ca9bcc3b97f33c23e","26e896452aa4406689f729175f33ea72","ca473ed971ed463a8f4c91e9b2e92c33","5b79f0256f444de2b52ee977f4426d7e","f511889645db430d814cddb171c192a3","43858ed2b4a44878b71336a6e57313f1"]},"id":"IrVEGmQ_Ep5y","executionInfo":{"status":"ok","timestamp":1762276105345,"user_tz":-330,"elapsed":33269,"user":{"displayName":"Ayush Bhakat","userId":"01025510492377215074"}},"outputId":"9c44fb8c-66d6-4a72-be7a-82c73f17126c"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","üöÄ INITIALIZING TRAINER\n","======================================================================\n","Unsloth: Switching to float32 training since model cannot work with float16\n"]},{"output_type":"display_data","data":{"text/plain":["Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/1800 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"883367a2ebcf40b19b735f1ad3b520f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Unsloth: Tokenizing [\"text\"] (num_proc=6):   0%|          | 0/200 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbdc285d574e408b841830f8accd4301"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The model is already on multiple devices. Skipping the move to device specified in `args`.\n"]},{"output_type":"stream","name":"stdout","text":["‚úÖ Trainer initialized!\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 6: TRAIN THE MODEL\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"üèãÔ∏è STARTING TRAINING\")\n","print(\"=\"*70)\n","print(\"This will take approximately 15-30 minutes on T4 GPU\")\n","print(\"You can monitor progress below...\")\n","print(\"=\"*70 + \"\\n\")\n","\n","# Start training\n","trainer.train()\n","\n","print(\"\\n‚úÖ TRAINING COMPLETE!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":614},"id":"VF5IqUHWEs8T","executionInfo":{"status":"ok","timestamp":1762281821999,"user_tz":-330,"elapsed":5708582,"user":{"displayName":"Ayush Bhakat","userId":"01025510492377215074"}},"outputId":"673ffbee-a8d7-4eef-d478-736b98c5487d"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","üèãÔ∏è STARTING TRAINING\n","======================================================================\n","This will take approximately 15-30 minutes on T4 GPU\n","You can monitor progress below...\n","======================================================================\n","\n"]},{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n","   \\\\   /|    Num examples = 1,800 | Num Epochs = 15 | Total steps = 855\n","O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 8\n","\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 8 x 1) = 32\n"," \"-____-\"     Trainable parameters = 3,796,992 of 271,895,168 (1.40% trained)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='855' max='855' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [855/855 1:34:59, Epoch 15/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>100</td>\n","      <td>1.138100</td>\n","      <td>1.099737</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.913100</td>\n","      <td>0.926966</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.987500</td>\n","      <td>0.935253</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.879400</td>\n","      <td>0.938372</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.833200</td>\n","      <td>0.802215</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.891100</td>\n","      <td>0.802767</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.804800</td>\n","      <td>0.776491</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.803600</td>\n","      <td>0.778823</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","‚úÖ TRAINING COMPLETE!\n"]}]},{"cell_type":"code","source":["# ============================================================================\n","# STEP 7: SAVE MODEL\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"üíæ SAVING MODEL\")\n","print(\"=\"*70)\n","\n","# Create output directory\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","# Save LoRA adapters\n","final_model_path = os.path.join(OUTPUT_DIR, \"final_model\")\n","model.save_pretrained(final_model_path)\n","tokenizer.save_pretrained(final_model_path)\n","print(f\"‚úÖ LoRA adapters saved to: {final_model_path}\")\n","\n","# Save merged 16-bit model\n","merged_model_path = os.path.join(OUTPUT_DIR, \"final_model_merged_16bit\")\n","model.save_pretrained_merged(merged_model_path, tokenizer, save_method=\"merged_16bit\")\n","print(f\"‚úÖ Merged 16-bit model saved to: {merged_model_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":343},"id":"mKhmCfmsEwpk","executionInfo":{"status":"error","timestamp":1762283066023,"user_tz":-330,"elapsed":39,"user":{"displayName":"Ayush Bhakat","userId":"01025510492377215074"}},"outputId":"ccfd3e6a-63d1-42f6-dbaf-2702cd2abce9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","üíæ SAVING MODEL\n","======================================================================\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'os' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1570690250.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Create output directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Save LoRA adapters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"]}]},{"cell_type":"code","source":["# # # Step 1 ‚Äî Zip the folder\n","!zip -r hider_sft.zip /content/models/hider_sft/\n","\n","# Step 2 ‚Äî Download the ZIP\n","from google.colab import files\n","files.download(\"hider_sft.zip\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"RoDnhTjIEza5","executionInfo":{"status":"ok","timestamp":1762272758428,"user_tz":-330,"elapsed":65,"user":{"displayName":"Ayush Bhakat","userId":"01025510492377215074"}},"outputId":"90e5dbf3-6157-498e-e815-7936241ecada"},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_072918f1-df29-4fdc-94bf-ed1f9e6d1714\", \"seeker_sft.zip\", 542261135)"]},"metadata":{}}]}]}